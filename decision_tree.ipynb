{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from typing import Any, Optional, List, Tuple\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vector = List[Any]\n",
    "Matrix = List[Vector]\n",
    "\n",
    "\n",
    "class Node:\n",
    "    def __init__(\n",
    "        self,\n",
    "        feature=None,\n",
    "        threshold=None,\n",
    "        left: Optional[\"Node\"] = None,\n",
    "        right: Optional[\"Node\"] = None,\n",
    "        *,\n",
    "        value: Any = None\n",
    "    ):\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        self.left = left  # the left node that we are pointing to\n",
    "        self.right = right  # the left node that we are pointing to\n",
    "        self.value = value  # value if this is a leaf node\n",
    "\n",
    "    def is_leaf_node(self) -> bool:\n",
    "        \"\"\"Returns true if this is a leaf node.\"\"\"\n",
    "        return self.value is not None\n",
    "\n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(\n",
    "        self,\n",
    "        min_samples_split: int = 2,\n",
    "        max_depth: int = 100,\n",
    "        n_features: int | None = None,\n",
    "    ):\n",
    "        self.min_samples_split: int = min_samples_split\n",
    "        self.max_depth: int = max_depth\n",
    "        self.n_features_to_use: int = n_features\n",
    "        self.root = None\n",
    "\n",
    "    def fit(self, xs: Matrix, ys: Vector) -> None:\n",
    "        \"\"\"Fit training data.\"\"\"\n",
    "        # check if n_features is less than actual feature\n",
    "        # if more than actual feature, use actual feature\n",
    "        n_features = xs.shape[1]\n",
    "        if not self.n_features_to_use:\n",
    "            self.n_features_to_use = n_features\n",
    "        else:\n",
    "            self.n_features_to_use = min(self.n_features_to_use, n_features)\n",
    "        # create tree\n",
    "        self.root = self._grow_tree(xs, ys)\n",
    "\n",
    "    def _grow_tree(self, xs: Matrix, ys: Vector, depth: int = 0) -> Node:\n",
    "        \"\"\"Recursive function to split nodes until specified condition is met.\"\"\"\n",
    "        n_samples, n_features = xs.shape\n",
    "        n_labels = len(np.unique(ys))\n",
    "\n",
    "        # base case\n",
    "        # return leaf node\n",
    "        if (\n",
    "            depth >= self.max_depth  # if max depth is reached\n",
    "            or n_labels == 1  # if the remaining class is only 1\n",
    "            or n_samples < self.min_samples_split  # if reach min number of samples\n",
    "        ):\n",
    "            return Node(value=self._most_common_label(ys))\n",
    "\n",
    "        # recursive case\n",
    "        # find the best split\n",
    "        feature_idxs = np.random.choice(n_features, self.n_features_to_use, replace=False)\n",
    "        best_feature, best_threshold = self._best_split(xs, ys, feature_idxs)\n",
    "        # create child nodes\n",
    "        left_idxs, right_idxs = self._split(xs[:, best_feature], best_threshold)\n",
    "        left = self._grow_tree(xs[left_idxs, :], ys[left_idxs], depth + 1)\n",
    "        right = self._grow_tree(xs[right_idxs, :], ys[right_idxs], depth + 1)\n",
    "        return Node(best_feature, best_threshold, left, right)\n",
    "\n",
    "    def _best_split(self, xs: Matrix, ys: Vector, feature_idxs: Vector) -> Tuple[Vector, float]:\n",
    "        \"\"\"Find the feature and threshold that maximize information gain.\"\"\"\n",
    "        best_gain = -1  # init\n",
    "        split_idx, split_threshold = None, None  # init\n",
    "\n",
    "        # iterate through each feature\n",
    "        for i in feature_idxs:\n",
    "            xs_col = xs[:, i]  # get the entire feature (i.e. col in a DF)\n",
    "            thresholds = np.unique(xs_col)  # get all possible value of this feature\n",
    "            # iterate through each value in this feature\n",
    "            for threshold in thresholds:\n",
    "                # calculate the information gain\n",
    "                gain = self._information_gain(xs_col, ys, threshold)\n",
    "                if gain > best_gain:\n",
    "                    best_gain = gain\n",
    "                    split_idx = i\n",
    "                    split_threshold = threshold\n",
    "        return split_idx, split_threshold\n",
    "\n",
    "    def _information_gain(self, xs_col: Vector, ys: Vector, threshold: float) -> float:\n",
    "        \"\"\"Calculates information gain of a split.\n",
    "        entropy(parent) - weighted_avg(entropy(child))\n",
    "        \"\"\"\n",
    "        left_idx, right_idx = self._split(xs_col, threshold)  # create children\n",
    "        \n",
    "        # if the the class is still on one of the split, then the IG = 0\n",
    "        # i.e. the split has no effect\n",
    "        if len(left_idx) == 0 or len(right_idx) == 0:\n",
    "            return 0\n",
    "        \n",
    "        # else, calculate weighted entropy of child\n",
    "        parent_ent = self._entropy(ys)  # get parent entropy\n",
    "        n = len(ys)\n",
    "        n_left= len(left_idx)\n",
    "        n_right = len(right_idx)\n",
    "        ent_left = self._entropy(ys[left_idx])\n",
    "        ent_right = self._entropy(ys[right_idx])\n",
    "        children_ent = (ent_left * n_left / n) + (ent_right * n_right / n) # weighted child ent\n",
    "        return parent_ent - children_ent # information gain\n",
    "\n",
    "    def _split(self, xs_col: Vector, threshold: float) -> Tuple[Vector, Vector]:\n",
    "        \"\"\"Returns an index of split data points based on threshold.\"\"\"\n",
    "        left_idx = np.argwhere(xs_col <= threshold).flatten()\n",
    "        right_idx = np.argwhere(xs_col > threshold).flatten()\n",
    "        return left_idx, right_idx\n",
    "\n",
    "    def _entropy(self, ys: Vector) -> float:\n",
    "        \"\"\"\n",
    "        - sum(prob(x) * log2(prob(x)))\n",
    "        where prob(x) = count(x) / num_data_point\n",
    "        \"\"\"\n",
    "        n = len(ys)\n",
    "        counter = Counter(ys)\n",
    "        return -1 * sum(\n",
    "            (count / n) * (math.log2(count / n)) for count in counter.values()\n",
    "        )\n",
    "\n",
    "    def _most_common_label(self, labels: Vector) -> Any:\n",
    "        \"\"\"Returns the most common label.\"\"\"\n",
    "        return Counter(labels).most_common(1)[0][0]\n",
    "\n",
    "    def predict(self, xs: Matrix) -> Vector:\n",
    "        \"\"\"Predict a set of samples.\"\"\"\n",
    "        return np.array([self._traverse_tree(x, self.root) for x in xs])\n",
    "\n",
    "    def _traverse_tree(self, x, node: Node) -> Any:\n",
    "        \"\"\"Traverse the tree recursively until meeting leaf node.\"\"\"\n",
    "        # base case\n",
    "        if node.is_leaf_node():\n",
    "            return node.value\n",
    "        # recursive case: go to left node\n",
    "        elif x[node.feature] <= node.threshold:\n",
    "            return self._traverse_tree(x, node.left)\n",
    "        # recursive case: go to right node\n",
    "        else:\n",
    "            return self._traverse_tree(x, node.right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9344262295081968"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = load_breast_cancer()\n",
    "xs, ys = data.data, data.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    xs, ys, test_size=0.32, random_state=42\n",
    ")\n",
    "\n",
    "dt = DecisionTree(max_depth=10)\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "acc = sum(y_pred == y_test) / len(y_test)\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explaination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How does recursive funtion works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3628800"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def factorial(n):\n",
    "    # base case\n",
    "    if n == 0 or n == 1:\n",
    "        return 1\n",
    "    # recursive case\n",
    "    else:\n",
    "        return n * factorial(n - 1)\n",
    "\n",
    "\n",
    "factorial(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How does counter works?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'b'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_ys = [\"a\", \"a\", \"b\", \"b\", \"b\", \"c\"]\n",
    "DecisionTree()._most_common_label(sample_ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to calculate entropy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'a', 'b', 'b', 'b', 'c']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'b': 3, 'a': 2, 'c': 1})"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(sample_ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4591479170272448"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DecisionTree()._entropy(sample_ys) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4591479170272448"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-1 * (\n",
    "    (2 / len(sample_ys) * math.log2(2 / len(sample_ys)))  # class a\n",
    "    + (3 / len(sample_ys) * math.log2(3 / len(sample_ys)))  # class b\n",
    "    + (1 / len(sample_ys) * math.log2(1 / len(sample_ys)))  # class c\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What does np.argwhere do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 4])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_xs_col = np.array([1, 1, 3, 6, 10])\n",
    "threshold = 5\n",
    "np.argwhere(sample_xs_col > threshold).flatten()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
